# 爬虫 + 规则 + Ollama 分析 Pipeline 失真原因分析报告

**分析时间**: 2025-12-16  
**分析范围**: PowerChina 爬虫 + 规则评分 + qwen2.5:0.5b AI 分析  
**数据来源**: 数据库实际记录 + 代码逻辑审查

---

## 一、输入失真分析（最重要，根因 #1）

### 1.1 证据

**数据库实际数据**：
```
标题: [工程类]绵阳科技城新区人工智能大楼项目 消防工程采购实施前公示
raw_text 长度: 7 字符
raw_text 内容: "English"
```

**代码流程追踪**：
1. `fetch_detail_by_click()` 返回 HTML（207161 字符）✅
2. `extract_raw_text(html)` 提取后 → 仅 7 字符 ❌
3. 传入 `analyze_notice(raw_text="English", ...)` ❌

**提取逻辑问题**（`powerchina_crawler.py:347-360`）：
```python
def extract_raw_text(self, html: str) -> str:
    soup = BeautifulSoup(html, 'html.parser')
    content_elem = soup.find(['div', 'article', 'section'], 
                            class_=re.compile(r'content|detail|main|body', re.I))
    if not content_elem:
        content_elem = soup.find('body')  # 回退到 body
    
    if content_elem:
        for script in content_elem(["script", "style", "nav", "header", "footer"]):
            script.decompose()
        return content_elem.get_text(separator='\n', strip=True)
    
    return ''
```

### 1.2 问题诊断

**问题 1：选择器未命中详情区域**
- SPA 页面点击后，详情可能出现在：
  - 弹窗（`.el-dialog__body`）
  - 抽屉（`.el-drawer__body`）
  - 展开行（`.el-table__expanded-cell`）
- 但 `extract_raw_text()` 只查找 `div/article/section` 且 class 包含 `content|detail|main|body`
- **结果**：未命中，回退到 `body`，提取到的是整个页面框架（包含导航、脚本、语言标识等）

**问题 2：提取到页面元数据而非正文**
- 当回退到 `body` 时，提取的文本包含：
  - HTML lang 属性值（"English"）
  - 导航菜单文本
  - 脚本注入的文本
  - **但缺少真正的公告正文**

**问题 3：输入质量不足以支撑业务判断**
- `raw_text="English"` 无法提供：
  - ❌ 项目地点
  - ❌ 项目范围/内容
  - ❌ 资质要求
  - ❌ 钢结构吨位
  - ❌ 投标截止时间
- **结论**：LLM 被迫在"信息几乎为零"的情况下做判断

### 1.3 影响评估

**直接影响**：
- 规则评分：`rule_score("English", {})` → 0 分（无匹配）
- AI 分析：模型看到的是 "English" + 规则评分 0，被迫"编造"结论

**间接影响**：
- 所有后续判断（地域、范围、资质、规模）都基于错误输入
- 导致"看似完整但业务上不可信"的输出

---

## 二、信息缺失 vs 明确不匹配的混淆问题

### 2.1 证据

**数据库案例**：
```
score: 100
label: RECOMMEND
summary: "招标公告中未明确地域和项目类型，且不支持所有资质要求。"
```

**矛盾分析**：
- `fit_score=100` 表示"完美适配"
- `summary` 说"未明确地域和项目类型"（信息缺失）
- `summary` 又说"不支持所有资质要求"（明确不匹配）
- **逻辑矛盾**：信息缺失 ≠ 明确不匹配，但模型混为一谈

### 2.2 问题诊断

**Prompt 结构问题**（`prompts.py:73-79`）：
```
## 任务要求
1. 基于规则评分结果，结合招标公告内容，给出最终适配度评分（0-100）
2. 确定推荐标签：RECOMMEND（强烈推荐，≥70分）、REVIEW（需审核，40-69分）、SKIP（不推荐，<40分）
...
```

**缺失的约束**：
- ❌ 未明确区分"信息缺失"（UNKNOWN）和"明确不匹配"（LOW）
- ❌ 未要求模型在信息不足时降低 confidence
- ❌ 未要求模型在 summary 中明确标注"信息不足，需人工确认"

**后处理逻辑缺失**（`analyzer.py:81-113`）：
- Schema 校验只检查格式（fit_score 范围、label 枚举）
- ❌ **没有一致性校验**：score vs label vs summary 的逻辑一致性
- ❌ **没有置信度检查**：当输入质量差时，应该强制降低 score

### 2.3 影响评估

**模型行为**：
- 当输入为 "English" 时，模型看到规则评分 0，但被要求"给出最终适配度评分"
- 模型可能：
  1. 过度自信：给出高分（100）但 summary 暴露矛盾
  2. 过度保守：给出低分（0）但 summary 说"无法确定"
- **结果**：输出看似完整，但内部逻辑不一致

---

## 三、Score / Label / Summary 不一致的原因

### 3.1 证据

**案例 1**：
```
fit_score: 100
fit_label: RECOMMEND
summary: "招标公告中未明确地域和项目类型，且不支持所有资质要求。"
```

**案例 2**：
```
fit_score: -10  (超出范围，被修正为 0)
fit_label: SKIP
summary: "招标公告未匹配到明显适配条件，如项目类型和业务范围不匹配。"
```

### 3.2 问题诊断

**根因 1：缺乏强约束**
- Schema 定义（`schema.py:20-25`）只约束了**类型和范围**：
  ```python
  fit_score: int = Field(ge=0, le=100)
  fit_label: Literal["RECOMMEND", "REVIEW", "SKIP"]
  ```
- ❌ **没有业务逻辑约束**：
  - score ≥ 70 必须对应 RECOMMEND
  - summary 必须与 score/label 一致
  - 当 region_match=UNKNOWN 时，score 不应过高

**根因 2：模型输出不稳定**
- qwen2.5:0.5b 是 0.5B 参数的小模型
- 在输入质量差的情况下，容易出现：
  - 数值输出不稳定（-10, 100, 50 随机）
  - 文本输出与数值不一致

**根因 3：后处理只做格式修正，不做逻辑修正**
- `analyzer.py:84-85` 只修正范围：
  ```python
  parsed_json['fit_score'] = max(0, min(100, int(parsed_json['fit_score'])))
  ```
- ❌ 没有根据 summary/reasons 反向修正 score
- ❌ 没有根据 score 修正 label

### 3.3 影响评估

**用户困惑**：
- 看到 `fit_score=100, label=RECOMMEND`，但 summary 说"未明确"，不知道该信哪个
- 系统输出"看似完整但不可信"

---

## 四、决策责任分配错误

### 4.1 证据

**规则评分逻辑**（`score_rules.py:166-238`）：
- 地域评分：有明确规则（四川 30 分，周边递减）✅
- 规模评分：有明确规则（200-3000 吨范围）✅
- 范围评分：有明确规则（关键词匹配）✅
- 资质评分：有明确规则（关键词匹配）✅

**但规则评分结果**：
- 当 `raw_text="English"` 时，所有规则都返回 0 分
- `rule_reasons = ["未匹配到明显适配条件"]`
- `rule_risk_flags = ["地域不在优先范围内", "项目类型或业务范围匹配度较低", "资质要求可能不完全匹配"]`

**问题**：规则已经判断"信息不足"，但系统仍然把判断权交给 LLM

### 4.2 问题诊断

**责任分配错误**：

1. **规则应该负责**：
   - ✅ 事实提取（地域、吨位、资质关键词）
   - ✅ 明确匹配/不匹配的判断
   - ❌ **当前缺失**：信息不足时的"拒绝判断"机制

2. **LLM 被要求负责**：
   - ❌ 在输入几乎为空时，仍然要求"给出最终适配度评分"
   - ❌ 被迫在"事实不足"的情况下输出结论

**Prompt 问题**（`prompts.py:74`）：
```
1. 基于规则评分结果，结合招标公告内容，给出最终适配度评分（0-100）
```
- ❌ 未说明：当规则评分 0 且输入为空时，应该返回 UNKNOWN 或拒绝判断
- ❌ 未说明：LLM 的职责是"补充规则无法覆盖的语义理解"，而不是"在无信息时编造结论"

### 4.3 影响评估

**系统行为**：
- 规则说"信息不足"（0 分）
- LLM 被迫"必须给出分数"（100 或 0）
- **结果**：LLM 输出看似完整，但基于错误输入

---

## 五、模型能力与任务复杂度是否匹配

### 5.1 证据

**模型规格**：
- qwen2.5:0.5b：0.5B 参数，约 397MB
- 定位：轻量级、快速推理

**任务复杂度**：
1. 理解公司业务画像（地域优先级、项目类型、规模范围、资质要求）
2. 理解规则评分结果（数值 + 原因 + 风险提示）
3. 从几乎为空的输入中提取关键信息
4. 综合判断适配度（0-100 分）
5. 生成一致的 summary、reasons、risk_flags
6. 输出严格 JSON 格式

**实际表现**：
- ✅ JSON 格式输出基本稳定（有 fallback 机制）
- ❌ 数值输出不稳定（-10, 100, 50 随机）
- ❌ 文本与数值不一致（score=100 但 summary 说"未明确"）
- ❌ 在输入质量差时，过度自信或过度保守

### 5.2 问题诊断

**能力边界**：
- qwen2.5:0.5b 适合：
  - ✅ 简单分类任务
  - ✅ 格式化的信息提取
  - ✅ 基于明确规则的判断
- ❌ **不适合**：
  - 在信息几乎为零时做复杂推理
  - 保持数值与文本的一致性
  - 理解"信息不足"与"明确不匹配"的区别

**任务设定超出能力**：
- 当前 prompt 要求模型"必须给出结论"，即使输入为空
- 小模型在压力下容易：
  1. 过度自信：给出高分但 summary 暴露矛盾
  2. 过度保守：给出低分但无法区分"信息不足"和"不匹配"

### 5.3 影响评估

**"自信但不可靠"的输出模式**：
- 模型输出格式完整（JSON 结构正确）
- 但内容不可信（score 与 summary 矛盾）
- **用户看到完整输出，但无法信任**

---

## 六、优先级排序的结论

### 6.1 前 3 个根因（按影响力排序）

#### 🥇 根因 #1：输入失真（工程设计问题）

**问题**：`extract_raw_text()` 从 SPA 页面提取正文失败，导致传入 LLM 的 `raw_text` 几乎为空（如 "English" 7 字符）

**证据**：
- 数据库显示 `raw_text` 长度仅 7 字符
- 点击后获取的 HTML 有 207161 字符，但提取后只剩 7 字符
- 提取逻辑未命中详情区域，回退到 `body`，提取到页面元数据

**影响**：
- 直接导致 LLM 在"信息几乎为零"的情况下做判断
- 所有后续失真都源于此

**分类**：**工程设计问题**（选择器设计不当、缺少 SPA 详情区域识别）

---

#### 🥈 根因 #2：决策责任分配错误（约束缺失）

**问题**：规则已经判断"信息不足"（0 分），但系统仍然要求 LLM"必须给出结论"，LLM 被迫在事实不足时输出判断

**证据**：
- 规则评分 0 分，`rule_reasons = ["未匹配到明显适配条件"]`
- Prompt 要求"给出最终适配度评分"，未说明信息不足时的处理
- 导致 score=100 但 summary 说"未明确"的矛盾

**影响**：
- LLM 输出看似完整，但基于错误输入
- 用户看到矛盾的结果（高分但 summary 说"未明确"）

**分类**：**约束缺失**（缺少"信息不足时拒绝判断"的机制、缺少规则与 LLM 的责任边界）

---

#### 🥉 根因 #3：Score/Label/Summary 一致性校验缺失（约束缺失）

**问题**：Schema 校验只检查格式（类型、范围），不检查业务逻辑一致性（score vs label vs summary）

**证据**：
- `fit_score=100, fit_label=RECOMMEND` 但 `summary="未明确地域和项目类型"`
- 后处理只修正数值范围（-10 → 0），不修正逻辑一致性

**影响**：
- 输出看似完整，但内部矛盾
- 用户无法信任结果

**分类**：**约束缺失**（缺少一致性校验逻辑）

---

### 6.2 次要根因

#### 根因 #4：模型能力与任务复杂度不匹配（模型能力问题）

**问题**：qwen2.5:0.5b 在输入质量差时，无法保持数值与文本的一致性

**影响**：加剧了"自信但不可靠"的输出模式

**分类**：**模型能力问题**（但可以通过更好的 prompt 设计和约束来缓解）

---

#### 根因 #5：信息缺失 vs 明确不匹配的混淆（Prompt 设计问题）

**问题**：Prompt 未明确区分"信息缺失"（UNKNOWN）和"明确不匹配"（LOW）

**影响**：模型把"未明确"当作"不支持"来处理

**分类**：**Prompt 设计问题**（可以通过改进 prompt 解决）

---

## 七、核心问题回答

### 👉 "为什么现在系统会得出看似完整、但业务上不可信的推断结果？"

**答案**：

1. **输入失真**（根因 #1）：
   - `extract_raw_text()` 从 SPA 页面提取失败，传入 LLM 的 `raw_text` 几乎为空
   - LLM 被迫在"信息几乎为零"的情况下做判断

2. **责任分配错误**（根因 #2）：
   - 规则已经判断"信息不足"，但系统仍然要求 LLM"必须给出结论"
   - LLM 在压力下输出看似完整但不可信的结果

3. **一致性校验缺失**（根因 #3）：
   - 系统只检查格式，不检查业务逻辑一致性
   - 导致 score=100 但 summary 说"未明确"的矛盾输出

**根本原因**：**工程设计问题 + 约束缺失**

- 工程设计问题：SPA 详情提取逻辑设计不当
- 约束缺失：缺少"信息不足时拒绝判断"的机制、缺少一致性校验

**结果**：系统输出格式完整（JSON 结构正确），但内容不可信（基于错误输入、内部矛盾）

---

## 八、改进方向建议（仅方向，不涉及具体代码）

### 8.1 输入失真修复
- 改进 `extract_raw_text()`：优先查找弹窗/抽屉/展开行的详情区域
- 添加输入质量检查：当 `raw_text` 长度 < 阈值时，拒绝分析或标记为"信息不足"

### 8.2 责任分配优化
- 规则增加"信息不足"判断：当规则评分 0 且输入质量差时，直接返回 UNKNOWN，不调用 LLM
- Prompt 明确 LLM 职责：只在"有足够信息但需要语义理解"时调用

### 8.3 一致性校验
- 添加业务逻辑校验：score vs label vs summary 的一致性
- 当检测到矛盾时，强制降级为 REVIEW 或拒绝判断

### 8.4 模型能力匹配
- 改进 Prompt：明确区分"信息缺失"和"明确不匹配"
- 添加置信度机制：当输入质量差时，强制降低 score 上限

---

**报告结束**

